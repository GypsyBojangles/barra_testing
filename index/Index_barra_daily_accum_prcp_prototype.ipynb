{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "from osgeo import ogr\n",
    "from osgeo import osr\n",
    "\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "from datacube import Datacube\n",
    "from datacube.index.hl import Doc2Dataset\n",
    "from datacube.utils import changes\n",
    "\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "def print_dict(doc):\n",
    "    print(json.dumps(doc, indent=4, sort_keys=True, cls=NumpySafeEncoder))\n",
    "\n",
    "def find_datasets(path: Path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    path = sorted(path.glob('**/*.tiff'))\n",
    "    pattern = re.compile(r'(?P<year>\\d{4})(?P<month>\\d{2})(?P<day>\\d{2})_total_accum_prcp.tiff')\n",
    "    datasets = defaultdict(dict)\n",
    "    for tifffile in path:\n",
    "        match = pattern.search(str(tifffile))\n",
    "        if match:\n",
    "            year, month, day = match.groups()\n",
    "            dataset = year + month + day\n",
    "            datasets[dataset] = tifffile\n",
    "    return datasets\n",
    "\n",
    "def generate_product_defn():\n",
    "    return {\n",
    "        'name': 'accum_prcp_daily',\n",
    "        'metadata_type': 'eo',\n",
    "        'metadata': {\n",
    "            'product_type': 'accum_prcp_daily',\n",
    "            'format' : { 'name': 'GeoTIFF'}\n",
    "        },\n",
    "        'storage': {\n",
    "            'crs': 'GEOGCS[\"unknown\",DATUM[\"unknown\",SPHEROID[\"Sphere\",6371229,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]]',\n",
    "            'resolution': {\n",
    "                'latitude': -0.1100000051935545453,\n",
    "                'longitude': 0.1100000051935545453\n",
    "            },\n",
    "            'origin': { 'longitude':65, 'latitude':19.48}\n",
    "        },\n",
    "        'description': 'BARRA Daily precipitation accumulation',\n",
    "        'measurements': [\n",
    "            {\n",
    "                'name':'accum_prcp',\n",
    "                'dtype':'float64',\n",
    "                'nodata': -1073741824,\n",
    "                'units':'kg m-2'\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def generate_dataset_doc(dataset_name, dataset):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    sample_tifffile = dataset\n",
    "    sample_tifffile_gdal = f'{sample_tifffile}'\n",
    "    creation_time = datetime.fromtimestamp(sample_tifffile.stat().st_mtime)\n",
    "    geo_ref_points, spatial_ref = get_grid_spatial_projection(\n",
    "        sample_tifffile_gdal)\n",
    "    \n",
    "\n",
    "    start_time = datetime.strptime(name, '%Y%m%d')\n",
    "    \n",
    "    end_time = start_time + relativedelta(days=1) - timedelta(microseconds=1)\n",
    "    center_time = (end_time - start_time)/2 + start_time\n",
    "    docs = []\n",
    "    unique_ds_uri = f'{sample_tifffile.as_uri()}#{creation_time}#{start_time}'\n",
    "    doc = {\n",
    "        'id': str(uuid.uuid5(uuid.NAMESPACE_URL, unique_ds_uri)),\n",
    "        'product_type': 'accum_prcp_daily',\n",
    "        'creation_dt': str(creation_time),\n",
    "        'extent': {\n",
    "            'from_dt': str(start_time),\n",
    "            'to_dt': str(end_time),\n",
    "            'center_dt': str(center_time),\n",
    "            'coord': to_lat_long_extent(geo_ref_points),\n",
    "        },\n",
    "        'format': {'name': 'GeoTIFF'},\n",
    "        'grid_spatial': {\n",
    "            'projection': {\n",
    "                'geo_ref_points': geo_ref_points,\n",
    "                'spatial_reference': spatial_ref,\n",
    "            }\n",
    "        },\n",
    "        'image': {\n",
    "            'bands': {\n",
    "                'accum_prcp': {\n",
    "                    'path': '',\n",
    "                    'layer': '1',\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        'lineage': {'source_datasets': {}}\n",
    "    }\n",
    "    return ('file:'+str(dataset),doc)\n",
    "\n",
    "\n",
    "def to_lat_long_extent(geo_ref_points):\n",
    "    return {corner: {'lat': points['y'], 'lon': points['x']}\n",
    "for corner, points in geo_ref_points.items()}\n",
    "\n",
    "\n",
    "def get_grid_spatial_projection(fname):\n",
    "    with rasterio.open(fname, 'r') as img:\n",
    "        left, bottom, right, top = img.bounds\n",
    "        spatial_reference = str(str(getattr(img, 'crs_wkt', None) or img.crs.wkt))\n",
    "        geo_ref_points = {\n",
    "            'ul': {'x': left, 'y': top},\n",
    "            'ur': {'x': right, 'y': top},\n",
    "            'll': {'x': left, 'y': bottom},\n",
    "            'lr': {'x': right, 'y': bottom},\n",
    "        }\n",
    "        return geo_ref_points, spatial_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetType(name='accum_prcp_daily', id_=16)\n"
     ]
    }
   ],
   "source": [
    "dc = Datacube(config='datacube.conf',env='barra-dev')\n",
    "index = dc.index\n",
    "\n",
    "product_def = generate_product_defn()\n",
    "product = index.products.from_doc(product_def)\n",
    "indexed_product = index.products.add(product)\n",
    "print(indexed_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = Path('/g/data/u46/users/dg6911/BARRA_Daily/')\n",
    "datasets = find_datasets(path)\n",
    "resolver = Doc2Dataset(index)\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "    doc = generate_dataset_doc(name, dataset)\n",
    "    dataset, err = resolver(doc[1], doc[0])\n",
    "    try:\n",
    "        indexed_dataset = index.datasets.add(dataset)\n",
    "    except Exception as e:\n",
    "        logging.error(\"Couldn't index %s/%s\", path, name)\n",
    "        logging.exception(\"Exception\", e)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
