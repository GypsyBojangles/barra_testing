{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "import json\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import uuid\n",
    "from osgeo import ogr\n",
    "from osgeo import osr\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "from datacube import Datacube\n",
    "from datacube.index.hl import Doc2Dataset\n",
    "from datacube.utils import changes\n",
    "\n",
    "os.environ['GDAL_NETCDF_BOTTOMUP'] = 'NO'\n",
    "\n",
    "BARRA_VAR_NAME = 'av_sfc_temp'\n",
    "BARRA_DESCRIPTION = 'BARRA Hourly surface temperature'\n",
    "BARRA_UNIT = 'K'\n",
    "BARRA_PATH = '/g/data/ma05/BARRA_R/v1/forecast/spec/av_sfc_temp/'\n",
    "\n",
    "PRODUCT_NAME = 'barra_'+BARRA_VAR_NAME\n",
    "\n",
    "LOG = logging.getLogger(__name__)\n",
    "\n",
    "def print_dict(doc):\n",
    "    print(json.dumps(doc, indent=4, sort_keys=True, cls=NumpySafeEncoder))\n",
    "\n",
    "def find_datasets(path: Path):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    path = sorted(path.glob('**/*.nc'))\n",
    "    pattern = re.compile(r'(?P<barra_var>'+BARRA_VAR_NAME+')\\-(?P<barra_var_type>fc\\-spec)\\-(?P<barra_sampling_frequency>PT1H)\\-(?P<barra_domain>BARRA_R)\\-v(?P<barra_version>\\d{1}\\.?\\d?)\\-(?P<date>\\d{8})T(?P<time>\\d{4})Z\\.sub.nc')\n",
    "    datasets = defaultdict(dict)\n",
    "    for ncfile in path:\n",
    "        match = pattern.search(str(ncfile))\n",
    "        if match:\n",
    "            barra_var, barra_var_type, barra_sampling_frequency, barra_domain, barra_version, date, hour = match.groups()\n",
    "            dataset = barra_var + date + hour+ barra_domain + barra_version\n",
    "            datasets[dataset][barra_var] = ncfile\n",
    "    return datasets\n",
    "\n",
    "def generate_product_defn():\n",
    "    return {\n",
    "        'name': BARRA_VAR_NAME,\n",
    "        'metadata_type': 'eo',\n",
    "        'metadata': {\n",
    "            'product_type': PRODUCT_NAME,\n",
    "            'format' : { 'name': 'NetCDF'}\n",
    "        },\n",
    "        'storage': {\n",
    "            'crs': 'GEOGCS[\"unknown\",DATUM[\"unknown\",SPHEROID[\"Sphere\",6371229,0]],PRIMEM[\"Greenwich\",0],UNIT[\"degree\",0.0174532925199433,AUTHORITY[\"EPSG\",\"9122\"]]]',\n",
    "            'resolution': {\n",
    "                'latitude': 0.1100000035809413773,\n",
    "                'longitude': 0.1100000058540808734\n",
    "            },\n",
    "            'origin': { 'longitude':65, 'latitude':19.48}\n",
    "        },\n",
    "        'description': BARRA_DESCRIPTION,\n",
    "        'measurements': [\n",
    "            {\n",
    "                'name': BARRA_VAR_NAME,\n",
    "                'dtype':'float64',\n",
    "                'nodata': -1073741824,\n",
    "                'units':BARRA_UNIT\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "def generate_dataset_docs(dataset_name, dataset):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    sample_ncfile = dataset[BARRA_VAR_NAME]\n",
    "    sample_ncfile_gdal = f'NETCDF:{sample_ncfile}:{BARRA_VAR_NAME}'\n",
    "\n",
    "    creation_time = datetime.fromtimestamp(sample_ncfile.stat().st_mtime)\n",
    "    geo_ref_points, spatial_ref = get_grid_spatial_projection(\n",
    "        sample_ncfile_gdal)\n",
    "    \n",
    "    date = name[len(BARRA_VAR_NAME):len(BARRA_VAR_NAME)+12]\n",
    "\n",
    "    start_time = datetime.strptime(date, '%Y%m%d%H%M')\n",
    "    end_time = start_time + timedelta(hours=1) - timedelta(microseconds=1)\n",
    "    center_time = start_time + timedelta(minutes=30)\n",
    "    docs = []\n",
    "    for i in range(6):\n",
    "        unique_ds_uri = f'{sample_ncfile.as_uri()}#{creation_time}#{start_time+timedelta(hours=i)}'\n",
    "        doc = {\n",
    "            'id': str(uuid.uuid5(uuid.NAMESPACE_URL, unique_ds_uri)),\n",
    "            'product_type': PRODUCT_NAME,\n",
    "            'creation_dt': str(creation_time),\n",
    "            'extent': {\n",
    "                'from_dt': str(start_time+timedelta(hours=i)),\n",
    "                'to_dt': str(end_time+timedelta(hours=i)),\n",
    "                'center_dt': str(center_time+timedelta(hours=i)),\n",
    "                'coord': to_lat_long_extent(geo_ref_points),\n",
    "            },\n",
    "            'format': {'name': 'NetCDF'},\n",
    "            'grid_spatial': {\n",
    "                'projection': {\n",
    "                    'geo_ref_points': geo_ref_points,\n",
    "                    'spatial_reference': spatial_ref,\n",
    "                }\n",
    "            },\n",
    "            'image': {\n",
    "                'bands': {\n",
    "                    BARRA_VAR_NAME: {\n",
    "                        'path': '',\n",
    "                        'layer': BARRA_VAR_NAME,\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'lineage': {'source_datasets': {}}\n",
    "        }\n",
    "        docs.append(('file:'+str(dataset[BARRA_VAR_NAME])+'#part='+str(i),doc))\n",
    "    return docs\n",
    "\n",
    "\n",
    "def to_lat_long_extent(geo_ref_points):\n",
    "    return {corner: {'lat': points['y'], 'lon': points['x']}\n",
    "for corner, points in geo_ref_points.items()}\n",
    "\n",
    "\n",
    "def get_grid_spatial_projection(fname):\n",
    "    with rasterio.open(fname, 'r') as img:\n",
    "        left, bottom, right, top = img.bounds\n",
    "        spatial_reference = str(str(getattr(img, 'crs_wkt', None) or img.crs.wkt))\n",
    "        geo_ref_points = {\n",
    "            'ul': {'x': left, 'y': top},\n",
    "            'ur': {'x': right, 'y': top},\n",
    "            'll': {'x': left, 'y': bottom},\n",
    "            'lr': {'x': right, 'y': bottom},\n",
    "        }\n",
    "        return geo_ref_points, spatial_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetType(name='av_sfc_temp', id_=17)\n"
     ]
    }
   ],
   "source": [
    "dc = Datacube(config='datacube.conf',env='barra-dev')\n",
    "index = dc.index\n",
    "\n",
    "product_def = generate_product_defn()\n",
    "product = index.products.from_doc(product_def)\n",
    "indexed_product = index.products.add(product)\n",
    "print(indexed_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "path = Path(BARRA_PATH)\n",
    "datasets = find_datasets(path)\n",
    "resolver = Doc2Dataset(index)\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "    docs = generate_dataset_docs(name, dataset)\n",
    "    for doc in docs:       \n",
    "        dataset, err = resolver(doc[1], doc[0])\n",
    "        try:\n",
    "            indexed_dataset = index.datasets.add(dataset)\n",
    "        except Exception as e:\n",
    "            logging.error(\"Couldn't index %s/%s\", path, name)\n",
    "            logging.exception(\"Exception\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
