{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BARRA <> DEA Generate Daily Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datacube\n",
    "import rasterio\n",
    "import time\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datacube.helpers import write_geotiff\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_barra_data(filename, target_dataset, source_affine, nodata=-1073741824):\n",
    "    profile_override = {'nodata': nodata, 'transform': source_affine}\n",
    "    write_geotiff(filename, target_dataset, profile_override=profile_override)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_barra_data(source_dataset, target_variable='accum_prcp'):\n",
    "    temp_dataarray = source_dataset[target_variable].reindex(latitude=source_dataset[target_variable].latitude[::-1])\n",
    "    target_dataset = temp_dataarray.to_dataset()\n",
    "    target_dataset.attrs = temp_dataarray.attrs\n",
    "    return target_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before loading BARRA data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because GDAL struggles with the BARRA NetCDF format we have two choices:\n",
    "# we leave everything unmolested but exruiciatingly slow\n",
    "# or\n",
    "# we use the following directive. This helps GDAL read the file\n",
    "# metadata correctly but it has the unfortunate side effect of flipping our data.\n",
    "# Depending on what other data sourced you are reading from , you may need to \n",
    "# explicitly set this flag back to YES to avoid any unforeseen consequences\n",
    "os.environ['GDAL_NETCDF_BOTTOMUP'] = 'NO'\n",
    "\n",
    "# you will need a datacube confing:\n",
    "config = {\n",
    "    'db_hostname': 'agdcdev-db.nci.org.au',\n",
    "    'db_port': 6432,\n",
    "    'db_database': 'dg6911'\n",
    "}\n",
    "dc = datacube.Datacube(config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load BARRA faster using DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/g/data/v10/public/modules/dea-env/20190709/lib/python3.6/site-packages/distributed/dashboard/core.py:72: UserWarning: \n",
      "Port 8787 is already in use. \n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the diagnostics dashboard on a random port instead.\n",
      "  warnings.warn(\"\\n\" + msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:37286</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:39267/status' target='_blank'>http://127.0.0.1:39267/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>8</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>24.00 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:37286' processes=8 cores=8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dask\n",
    "import dask.distributed\n",
    "\n",
    "client = dask.distributed.Client(n_workers=8,\n",
    "                                 threads_per_worker=1,\n",
    "                                 memory_limit='3G',\n",
    "                                 ip='127.0.0.1')\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_daily_summary(day, month, year):\n",
    "    accum = dc.load(product='accum_prcp',\n",
    "             dask_chunks={'time':6},\n",
    "               time=year+'-'+month+'-'+day,\n",
    "               skip_broken_datasets=True)\n",
    "    affine = accum['accum_prcp'].affine\n",
    "    attrs = accum['accum_prcp'].attrs\n",
    "    loaded_accum = accum['accum_prcp'].compute()\n",
    "    filtered_sum = loaded_accum.where(loaded_accum >= 0, drop=True).sum(dim='time')\n",
    "    \n",
    "    ## turn back into dataset\n",
    "    total_day_accumprcp_dataset = filtered_sum.to_dataset()\n",
    "    total_day_accumprcp_dataset['accum_prcp'].attrs = attrs\n",
    "    total_day_accumprcp_dataset.attrs = attrs\n",
    "    \n",
    "    #flip\n",
    "    flipped_accum_prcp = flip_barra_data(total_day_accumprcp_dataset)\n",
    "\n",
    "\n",
    "    target_dir = '/g/data/u46/users/dg6911/BARRA_Daily/'+year+'/'+month+'/'\n",
    "    if not os.path.exists(target_dir):\n",
    "        os.makedirs(target_dir)\n",
    "    \n",
    "    ##write to disk\n",
    "    write_barra_data(target_dir+year+month+day+'_total_accum_prcp.tiff', flipped_accum_prcp, affine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in range(1990, 2020):\n",
    "    for month in range(1, 13):\n",
    "        for day in range(1, 32):\n",
    "            date = str(day).zfill(2)+'/'+str(month).zfill(2)+'/'+str(year)\n",
    "            try:\n",
    "                datetime.strptime(date, '%d/%m/%Y')\n",
    "                generate_daily_summary(str(day).zfill(2), str(month).zfill(2),str(year))\n",
    "            except ValueError:\n",
    "                print('The date {} is invalid'.format(date))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
